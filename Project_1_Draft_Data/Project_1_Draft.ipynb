{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08db4d0a-ae86-43be-9fa2-70ca865df80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (1.26.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (1.11.4)\n",
      "Requirement already satisfied: pandas>=1.0 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (2.1.4)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from pandas>=1.0->statsmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a42a46b-23c1-4100-9f01-78d3c1ad3772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c302be8-6806-4c13-88e2-50049c388873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012c06eb-3c4d-420d-8374-493b413d02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1680)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15f2c7cf-d0a2-4934-946e-e5012ac7e2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6276\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "# Read the cab rides and weather data\n",
    "cab_df = pd.read_csv(\"cab_rides.csv\")\n",
    "weather_df = pd.read_csv(\"weather.csv\")\n",
    "\n",
    "#print(cab_df.head(20))\n",
    "#print(weather_df.head(20))\n",
    "\n",
    "#print(weather_df.head())\n",
    "\n",
    "# Convert time_stamp to datetime format\n",
    "cab_df['date_time'] = pd.to_datetime(cab_df['time_stamp']/1000, unit='s')\n",
    "weather_df['date_time'] = pd.to_datetime(weather_df['time_stamp'], unit='s')\n",
    "\n",
    "#print(cab_df.head())\n",
    "\n",
    "merged_df = pd.merge(cab_df, weather_df, on='date_time', how='right')\n",
    "\n",
    "merged_df['price'].fillna(merged_df['price'].mean(), inplace=True)\n",
    "\n",
    "merged_df['rain'].fillna(0, inplace=True)\n",
    "\n",
    "#print(merged_df.isnull().sum())\n",
    "\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "#print(\"Shape after handling missing values:\", merged_df.shape)\n",
    "\n",
    "# Normalize price data by dividing price by distance\n",
    "merged_df['normalized_price'] = merged_df['price'] / merged_df['distance']\n",
    "\n",
    "merged_df['rush_hour'] = ((merged_df['date_time'].dt.hour >= 8) & (merged_df['date_time'].dt.hour < 10) |\n",
    "                          ((merged_df['date_time'].dt.hour >= 16) & (merged_df['date_time'].dt.hour < 18))).astype(int)\n",
    "\n",
    "merged_df['late_night'] = ((merged_df['date_time'].dt.hour >= 22) | (merged_df['date_time'].dt.hour < 6)).astype(int)\n",
    "\n",
    "merged_df['day_of_week'] = merged_df['date_time'].dt.dayofweek\n",
    "\n",
    "merged_df['heavy_rain'] = (merged_df['rain'] > 0.1).astype(int)\n",
    "\n",
    "#print(merged_df[['rain','heavy_rain']].describe())\n",
    "\n",
    "merged_df['weekend'] = ((merged_df['date_time'].dt.dayofweek == 4) & (merged_df['date_time'].dt.hour >= 18)) | \\\n",
    "                       (merged_df['date_time'].dt.dayofweek == 5) | \\\n",
    "                       ((merged_df['date_time'].dt.dayofweek == 6) & (merged_df['date_time'].dt.hour < 22)).astype(int)\n",
    "\n",
    "merged_df['weekend'] = merged_df['weekend'].astype(float)\n",
    "\n",
    "#print(merged_df.head(25))\n",
    "\n",
    "X = merged_df[['rush_hour', 'late_night', 'weekend', 'heavy_rain']]\n",
    "y = merged_df['surge_multiplier']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "#print(model.summary())\n",
    "print(weather_df.shape[0])\n",
    "print(merged_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "267e8d2f-d983-4849-991f-d09616841749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: - \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-arm64::conda==22.9.0=py39hca03da5_0\n",
      "  - defaults/osx-arm64::sip==6.7.12=py39h313beb8_0\n",
      "  - defaults/osx-arm64::anaconda-navigator==2.5.2=py39hca03da5_0\n",
      "  - defaults/osx-arm64::clyent==1.2.2=py39hca03da5_1\n",
      "  - defaults/osx-arm64::conda-repo-cli==1.0.75=py39hca03da5_0\n",
      "  - defaults/osx-arm64::anaconda-client==1.12.2=py39hca03da5_0\n",
      "  - defaults/osx-arm64::pyqt==5.15.10=py39h313beb8_0\n",
      "  - defaults/osx-arm64::navigator-updater==0.4.0=py39hca03da5_1\n",
      "  - defaults/noarch::conda-token==0.4.0=pyhd3eb1b0_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 24.1.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/scottpetersen/opt/miniconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  pkgs/main/osx-arm64::_py-xgboost-mutex-2.0-cpu_0 None\n",
      "  libxgboost         pkgs/main/osx-arm64::libxgboost-1.7.3-h313beb8_0 None\n",
      "  py-xgboost         pkgs/main/osx-arm64::py-xgboost-1.7.3-py39hca03da5_0 None\n",
      "  setuptools         pkgs/main/osx-arm64::setuptools-68.2.2-py39hca03da5_0 None\n",
      "  xgboost            pkgs/main/osx-arm64::xgboost-1.7.3-py39hca03da5_0 None\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "RemoveError: 'setuptools' is a dependency of conda and cannot be removed from\n",
      "conda's operating environment.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da37c54e-0d12-416a-8cec-3dda4f118f82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxg\u001b[39;00m\n\u001b[1;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m merged_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrush_hour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlate_night\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurge_multiplier\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xg\n",
    "X = merged_df[['rush_hour', 'late_night', 'day_of_week']]\n",
    "y = merged_df['surge_multiplier']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da7f0722-b004-4cbb-ba67-d72433f03032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distance cab_type   time_stamp_x              destination    source  price  \\\n",
      "0      1.22     Uber  1543397538000  Northeastern University  Back Bay   10.5   \n",
      "1      1.22     Uber  1543397538000  Northeastern University  Back Bay   10.5   \n",
      "2      1.22     Uber  1543397538000  Northeastern University  Back Bay   10.5   \n",
      "3      1.22     Uber  1543397538000  Northeastern University  Back Bay   10.5   \n",
      "4      1.22     Uber  1543397538000  Northeastern University  Back Bay   10.5   \n",
      "\n",
      "   surge_multiplier                                    id  \\\n",
      "0               1.0  85de4cd6-9dfb-42f1-a365-66ea58c2d3ca   \n",
      "1               1.0  85de4cd6-9dfb-42f1-a365-66ea58c2d3ca   \n",
      "2               1.0  85de4cd6-9dfb-42f1-a365-66ea58c2d3ca   \n",
      "3               1.0  85de4cd6-9dfb-42f1-a365-66ea58c2d3ca   \n",
      "4               1.0  85de4cd6-9dfb-42f1-a365-66ea58c2d3ca   \n",
      "\n",
      "                             product_id    name           date_time   temp  \\\n",
      "0  6f72dfc5-27f1-42e8-84db-ccc7a75f6969  UberXL 2018-11-28 09:32:18  33.54   \n",
      "1  6f72dfc5-27f1-42e8-84db-ccc7a75f6969  UberXL 2018-11-28 09:32:18  33.49   \n",
      "2  6f72dfc5-27f1-42e8-84db-ccc7a75f6969  UberXL 2018-11-28 09:32:18  33.59   \n",
      "3  6f72dfc5-27f1-42e8-84db-ccc7a75f6969  UberXL 2018-11-28 09:32:18  33.30   \n",
      "4  6f72dfc5-27f1-42e8-84db-ccc7a75f6969  UberXL 2018-11-28 09:32:18  34.17   \n",
      "\n",
      "             location  clouds  pressure  rain  time_stamp_y  humidity  wind  \n",
      "0            Back Bay    0.42    991.75   0.0    1543397538      0.83  5.90  \n",
      "1         Beacon Hill    0.42    991.80   0.0    1543397538      0.84  5.89  \n",
      "2   Boston University    0.42    991.81   0.0    1543397538      0.83  5.78  \n",
      "3              Fenway    0.42    991.82   0.0    1543397538      0.84  5.82  \n",
      "4  Financial District    0.42    991.74   0.0    1543397538      0.81  5.97  \n"
     ]
    }
   ],
   "source": [
    "cab_df = pd.read_csv(\"cab_rides.csv\")\n",
    "weather_df = pd.read_csv(\"weather.csv\")\n",
    "\n",
    "cab_df['date_time'] = pd.to_datetime(cab_df['time_stamp']/1000, unit='s')\n",
    "weather_df['date_time'] = pd.to_datetime(weather_df['time_stamp'], unit='s')\n",
    "\n",
    "merged_df = pd.merge(cab_df, weather_df, on='date_time', how='inner')\n",
    "\n",
    "merged_df['rain'].fillna(0, inplace=True)\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a11aa740-d74e-4b94-8f7d-2b670474f733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distance cab_type   time_stamp_x              destination    source  price  \\\n",
      "0      1.22     Uber  1543397538000  Northeastern University  Back Bay   10.5   \n",
      "1      1.22     Uber  1543397538000  Northeastern University  Back Bay   10.5   \n",
      "2      1.22     Uber  1543397538000  Northeastern University  Back Bay   10.5   \n",
      "3      1.22     Uber  1543397538000  Northeastern University  Back Bay   10.5   \n",
      "4      1.22     Uber  1543397538000  Northeastern University  Back Bay   10.5   \n",
      "\n",
      "   surge_multiplier                                    id  \\\n",
      "0               1.0  85de4cd6-9dfb-42f1-a365-66ea58c2d3ca   \n",
      "1               1.0  85de4cd6-9dfb-42f1-a365-66ea58c2d3ca   \n",
      "2               1.0  85de4cd6-9dfb-42f1-a365-66ea58c2d3ca   \n",
      "3               1.0  85de4cd6-9dfb-42f1-a365-66ea58c2d3ca   \n",
      "4               1.0  85de4cd6-9dfb-42f1-a365-66ea58c2d3ca   \n",
      "\n",
      "                             product_id    name  ... clouds  pressure rain  \\\n",
      "0  6f72dfc5-27f1-42e8-84db-ccc7a75f6969  UberXL  ...   0.42    991.75  0.0   \n",
      "1  6f72dfc5-27f1-42e8-84db-ccc7a75f6969  UberXL  ...   0.42    991.80  0.0   \n",
      "2  6f72dfc5-27f1-42e8-84db-ccc7a75f6969  UberXL  ...   0.42    991.81  0.0   \n",
      "3  6f72dfc5-27f1-42e8-84db-ccc7a75f6969  UberXL  ...   0.42    991.82  0.0   \n",
      "4  6f72dfc5-27f1-42e8-84db-ccc7a75f6969  UberXL  ...   0.42    991.74  0.0   \n",
      "\n",
      "   time_stamp_y  humidity  wind  normalized_price_z  \\\n",
      "0    1543397538      0.83  5.90           -0.437618   \n",
      "1    1543397538      0.84  5.89           -0.437618   \n",
      "2    1543397538      0.83  5.78           -0.437618   \n",
      "3    1543397538      0.84  5.82           -0.437618   \n",
      "4    1543397538      0.81  5.97           -0.437618   \n",
      "\n",
      "   normalized_price_distance  normalized_distance  normalized_name  \n",
      "0                   8.606557            -1.548655                0  \n",
      "1                   8.606557            -1.548655                0  \n",
      "2                   8.606557            -1.548655                0  \n",
      "3                   8.606557            -1.548655                0  \n",
      "4                   8.606557            -1.548655                0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df['price'] = pd.to_numeric(merged_df['price'])\n",
    "\n",
    "mean_price = merged_df['price'].mean()\n",
    "std_price = merged_df['price'].std()\n",
    "merged_df['normalized_price_z'] = (merged_df['price'] - mean_price) / std_price\n",
    "\n",
    "merged_df['normalized_price_distance'] = merged_df['price'] / merged_df['distance']\n",
    "\n",
    "mean_distance = merged_df['distance'].mean()\n",
    "std_distance = merged_df['distance'].std()\n",
    "merged_df['normalized_distance'] = (merged_df['distance'] - mean_distance) / std_distance\n",
    "\n",
    "name_mapping = {name: idx for idx, name in enumerate(merged_df['name'].unique())}\n",
    "merged_df['normalized_name'] = merged_df['name'].map(name_mapping)\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b39efd5-0244-4eed-8459-27fd06fd284f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance                     float64\n",
      "time_stamp_x                   int64\n",
      "price                        float64\n",
      "surge_multiplier             float64\n",
      "temp                         float64\n",
      "clouds                       float64\n",
      "pressure                     float64\n",
      "rain                         float64\n",
      "time_stamp_y                   int64\n",
      "humidity                     float64\n",
      "wind                         float64\n",
      "normalized_price_z           float64\n",
      "normalized_price_distance    float64\n",
      "normalized_distance          float64\n",
      "normalized_name                int64\n",
      "name                          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = merged_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "name_column = merged_df[['name']]\n",
    "\n",
    "numeric_and_name = pd.concat([numeric_columns, name_column], axis=1)\n",
    "\n",
    "numeric_and_name = numeric_and_name.dropna()\n",
    "\n",
    "print(numeric_and_name.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4df54c92-f37d-464e-96f5-de2b7b63cba4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['date_time'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnumeric_columns\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhumidity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X)\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['date_time'] not in index\""
     ]
    }
   ],
   "source": [
    "X = numeric_columns[['date_time', 'temp', 'rain', 'humidity']]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "y = merged_df['price']\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
