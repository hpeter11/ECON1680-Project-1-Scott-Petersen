{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08db4d0a-ae86-43be-9fa2-70ca865df80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (1.26.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (1.11.4)\n",
      "Requirement already satisfied: pandas>=1.0 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (2.1.4)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from pandas>=1.0->statsmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a42a46b-23c1-4100-9f01-78d3c1ad3772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/scottpetersen/opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe74a2a1-a63b-4801-99a1-c615bcff9200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING: The --force flag will be removed in a future conda release.\n",
      "         See 'conda update --help' for details about the --force-reinstall\n",
      "         and --clobber flags.\n",
      "\n",
      "\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-arm64::conda==22.9.0=py39hca03da5_0\n",
      "  - defaults/osx-arm64::sip==6.7.12=py39h313beb8_0\n",
      "  - defaults/osx-arm64::anaconda-navigator==2.5.2=py39hca03da5_0\n",
      "  - defaults/osx-arm64::clyent==1.2.2=py39hca03da5_1\n",
      "  - defaults/osx-arm64::conda-repo-cli==1.0.75=py39hca03da5_0\n",
      "  - defaults/osx-arm64::anaconda-client==1.12.2=py39hca03da5_0\n",
      "  - defaults/osx-arm64::pyqt==5.15.10=py39h313beb8_0\n",
      "  - defaults/osx-arm64::navigator-updater==0.4.0=py39hca03da5_1\n",
      "  - defaults/noarch::conda-token==0.4.0=pyhd3eb1b0_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 24.1.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/scottpetersen/opt/miniconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  brotli-python      pkgs/main/osx-arm64::brotli-python-1.0.9-py39hc377ac9_7 None\n",
      "  bzip2              pkgs/main/osx-arm64::bzip2-1.0.8-h80987f9_5 None\n",
      "  glib-tools         pkgs/main/osx-arm64::glib-tools-2.78.4-h313beb8_0 None\n",
      "  libglib            pkgs/main/osx-arm64::libglib-2.78.4-h0a96307_0 None\n",
      "  pcre2              pkgs/main/osx-arm64::pcre2-10.42-hb066dcc_0 None\n",
      "  pysocks            pkgs/main/osx-arm64::pysocks-1.7.1-py39hca03da5_0 None\n",
      "  setuptools         pkgs/main/osx-arm64::setuptools-68.2.2-py39hca03da5_0 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  bottleneck                           1.3.5-py39heec5a64_0 --> 1.3.7-py39hbda83bc_0 None\n",
      "  comm                                 0.1.2-py39hca03da5_0 --> 0.2.1-py39hca03da5_0 None\n",
      "  cryptography                        41.0.7-py39hd4332d6_0 --> 42.0.2-py39hd4332d6_0 None\n",
      "  glib                                    2.69.1-h514c7bf_2 --> 2.78.4-h313beb8_0 None\n",
      "  keyring                            23.13.1-py39hca03da5_0 --> 24.3.1-py39hca03da5_0 None\n",
      "  nest-asyncio                         1.5.6-py39hca03da5_0 --> 1.6.0-py39hca03da5_0 None\n",
      "  numpy                               1.26.3-py39h3b2db8e_0 --> 1.26.4-py39h3b2db8e_0 None\n",
      "  numpy-base                          1.26.3-py39ha9811e2_0 --> 1.26.4-py39ha9811e2_0 None\n",
      "  pandas                               2.1.4-py39h46d7db6_0 --> 2.2.1-py39h313beb8_0 None\n",
      "  pyopenssl                           23.2.0-py39hca03da5_0 --> 24.0.0-py39hca03da5_0 None\n",
      "  tzdata                                   2023d-h04d1e81_0 --> 2024a-h04d1e81_0 None\n",
      "  urllib3                              2.1.0-py39hca03da5_0 --> 2.1.0-py39hca03da5_1 None\n",
      "  xz                                       5.4.5-h80987f9_0 --> 5.4.6-h80987f9_0 None\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install xgboost --force conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f4ea20a-1b91-49e8-b8e9-f6ff4cb1dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180debf4-3522-4784-a1e6-689ff2b81a7e",
   "metadata": {},
   "source": [
    "It's unclear whether or not initializing a random seed will be of use yet, but I'm leaving it here for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012c06eb-3c4d-420d-8374-493b413d02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1680)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b3386-79c9-48ec-9b47-f9c1de8b658a",
   "metadata": {},
   "source": [
    "Use pandas to read in the CSVs to get the relevant dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa159d77-e6e8-4faa-8375-5d2484ed86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cab rides and weather data\n",
    "cab_df = pd.read_csv(\"cab_rides.csv\")\n",
    "weather_df = pd.read_csv(\"weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bdb915-5625-4593-89e3-1faf7f434c6f",
   "metadata": {},
   "source": [
    "The data for Uber and Lyfts has the following variables: distance, cab_type, time_stamp, destination, location, price, surge_multiplier, id, product_id, name, and date_time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02c38874-e328-4176-b425-53a65dfc1eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distance cab_type          time_stamp    destination          location  \\\n",
      "0      0.44     Lyft 2018-12-16 04:00:00  North Station  Haymarket Square   \n",
      "1      0.44     Lyft 2018-11-26 21:00:00  North Station  Haymarket Square   \n",
      "2      0.44     Lyft 2018-11-27 20:00:00  North Station  Haymarket Square   \n",
      "3      0.44     Lyft 2018-11-29 23:00:00  North Station  Haymarket Square   \n",
      "4      0.44     Lyft 2018-11-28 22:00:00  North Station  Haymarket Square   \n",
      "\n",
      "   price  surge_multiplier                                    id  \\\n",
      "0    5.0               1.0  424553bb-7174-41ea-aeb4-fe06d4f4b9d7   \n",
      "1   11.0               1.0  4bd23055-6827-41c6-b23b-3c491f24e74d   \n",
      "2    7.0               1.0  981a3613-77af-4620-a42a-0c0866077d1e   \n",
      "3   26.0               1.0  c2d88af2-d278-4bfd-a8d0-29ca77cc5512   \n",
      "4    9.0               1.0  e0126e1f-8ca9-4f2e-82b3-50505a09db9a   \n",
      "\n",
      "     product_id          name                     date_time  \n",
      "0     lyft_line        Shared 2018-12-16 09:30:07.890000128  \n",
      "1  lyft_premier           Lux 2018-11-27 02:00:23.676999936  \n",
      "2          lyft          Lyft 2018-11-28 01:00:22.197999872  \n",
      "3   lyft_luxsuv  Lux Black XL 2018-11-30 04:53:02.749000192  \n",
      "4     lyft_plus       Lyft XL 2018-11-29 03:49:20.223000064  \n"
     ]
    }
   ],
   "source": [
    "print(cab_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f33bf9-c913-453d-a4dc-c0f4bd9383ac",
   "metadata": {},
   "source": [
    "The data for weather has the following variables: temp, location, clouds, pressure, rain, time_stamp. Since data was only collected during one week in November, I am inclined not to use the temp variable. In addition, it may overlap with a 'late_night' variable that I am planning to use because low temperatures are related to the time of day, causing multicollinearity. For that reason, I will only be using the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a1b4551-b313-496c-a0fa-e66110ffd5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    temp            location  clouds  pressure    rain          time_stamp  \\\n",
      "0  42.42            Back Bay     1.0   1012.14  0.1228 2018-12-16 18:00:00   \n",
      "1  42.43         Beacon Hill     1.0   1012.15  0.1846 2018-12-16 18:00:00   \n",
      "2  42.50   Boston University     1.0   1012.15  0.1089 2018-12-16 18:00:00   \n",
      "3  42.11              Fenway     1.0   1012.13  0.0969 2018-12-16 18:00:00   \n",
      "4  43.13  Financial District     1.0   1012.14  0.1786 2018-12-16 18:00:00   \n",
      "\n",
      "   humidity   wind           date_time  \n",
      "0      0.77  11.25 2018-12-16 23:45:01  \n",
      "1      0.76  11.32 2018-12-16 23:45:01  \n",
      "2      0.76  11.07 2018-12-16 23:45:01  \n",
      "3      0.77  11.09 2018-12-16 23:45:01  \n",
      "4      0.75  11.49 2018-12-16 23:45:01  \n"
     ]
    }
   ],
   "source": [
    "print(weather_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd387b3d-1dc0-48d5-8a23-ca817b555fa9",
   "metadata": {},
   "source": [
    "pd.to_datetime can help to handle the current date/time variables which are stored in epochs. The cab_df dataframe has the epochs multiplied by 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61eee50e-bcf0-4cb9-9f1d-b702c4c6f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['time_stamp']=[datetime.fromtimestamp(i) for i in weather_df['time_stamp']]\n",
    "weather_df['time_stamp']=weather_df['time_stamp'].values.astype('datetime64[h]')\n",
    "\n",
    "cab_df['time_stamp']=[datetime.fromtimestamp(i/1000.0) for i in cab_df['time_stamp']]\n",
    "cab_df['time_stamp']=cab_df['time_stamp'].values.astype('datetime64[h]')\n",
    "cab_df.rename(columns={'source':'location'},inplace=True)\n",
    "\n",
    "weather_df.drop_duplicates(['time_stamp','location'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa271f6-5f85-4060-9e40-bca87af38eff",
   "metadata": {},
   "source": [
    "Merge dataframes on location and time using pd.merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1dce40-94b0-4183-9a39-4279ad34155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df=pd.merge(cab_df,weather_df,on=['location','time_stamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad919618-4cff-4e69-a2e1-aa530771ca2e",
   "metadata": {},
   "source": [
    "There are missing values in the price column so we fill them with the mean price for all of the prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98950c0d-0298-4d9f-8a3c-d782bfd78658",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['price'].fillna(merged_df['price'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457992a-4213-4a4b-ad88-d0faea7d294b",
   "metadata": {},
   "source": [
    "We also fill missing rain values with 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f35777-2219-4f9c-8b74-a117eadfadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['rain'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef08d102-8838-4891-87a1-27847a765026",
   "metadata": {},
   "source": [
    "Here, we need to normalize the price. Uber and Lyft rides have different distances and durations which factors into the cost. Sadly, ride duration is not an available variable, but we can divide the distance by the price to get an approximately normalized price.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c2838-526e-4a2c-ac17-005b7e562a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize price data by dividing price by distance\n",
    "merged_df['normalized_price'] = merged_df['price'] / merged_df['distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce140e08-d242-4287-9b3e-47b9e2e102c8",
   "metadata": {},
   "source": [
    "To determine when prices are high, a lot of time-based variables are necessary. It is not useful to include every day of the week as a variable because of multicollinearity issues, so instead, dummy variables will be used to single out specific windows of time that do not overlap. However, I will add a graph here to show the relationship between time and cab prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eb2b7c-55f6-4722-8c60-a5178cba9606",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['day_of_week'] = merged_df['time_stamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1a0db-30c3-4d68-bc58-e6fd126c9901",
   "metadata": {},
   "source": [
    "Here is the code for rush hour. Rush hour is the period from 8 AM to noon and 4 PM to 6 PM. I am only counting rush hour on weekdays to avoid overlap with the weekend variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194fba21-a0f2-4006-9b79-bf7a99ce1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['rush_hour'] = ((merged_df['time_stamp'].dt.hour >= 8) & (merged_df['time_stamp'].dt.hour < 12) |\n",
    "                          ((merged_df['time_stamp'].dt.hour >= 16) & (merged_df['time_stamp'].dt.hour < 18))).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6671d-0a00-4c3d-b6d5-fb2cd2e114d1",
   "metadata": {},
   "source": [
    "Late night is every single day from 10 PM to 6 AM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065048e6-c494-4640-845f-78e35ae554ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['late_night'] = ((merged_df['time_stamp'].dt.hour >= 22) | (merged_df['time_stamp'].dt.hour < 6)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc818c0d-36c0-4e94-bb7b-b386ae888105",
   "metadata": {},
   "source": [
    "Weekend is Fridays after 6 PM and until 10 PM, Saturdays from 6 AM until 10PM, and Sundays from 6 AM until 10PM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd8c78-a098-4350-8766-a3a62c06fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['weekend'] = ((merged_df['time_stamp'].dt.dayofweek == 4) & (merged_df['time_stamp'].dt.hour >= 18)) | \\\n",
    "                       (merged_df['time_stamp'].dt.dayofweek == 5) | \\\n",
    "                       ((merged_df['time_stamp'].dt.dayofweek == 6) & (merged_df['time_stamp'].dt.hour < 22)).astype(int)\n",
    "\n",
    "merged_df['weekend'] = merged_df['weekend'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd580b-6687-4dc7-9e91-fc33a121d752",
   "metadata": {},
   "source": [
    "This is the dummy variable for heavy rain. Heavy rain is defined for now as any period where there is more than 0.1 inch in an hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e97d79f-0b7d-467d-aebe-19974104b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['heavy_rain'] = (merged_df['rain'] > 0.1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effc017d-5151-4785-a4ef-664d7e64aa2f",
   "metadata": {},
   "source": [
    "This is the code for an OLS regression. I have coded up multiple values of X and Y to show the differences between the effects of different variables on X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15f2c7cf-d0a2-4934-946e-e5012ac7e2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       normalized_price   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.2645\n",
      "Date:                Fri, 08 Mar 2024   Prob (F-statistic):              0.901\n",
      "Time:                        20:10:11   Log-Likelihood:            -2.8173e+06\n",
      "No. Observations:              690107   AIC:                         5.635e+06\n",
      "Df Residuals:                  690102   BIC:                         5.635e+06\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          9.8260      0.027    362.962      0.000       9.773       9.879\n",
      "rush_hour     -0.0246      0.048     -0.509      0.610      -0.119       0.070\n",
      "late_night    -0.0231      0.039     -0.589      0.556      -0.100       0.054\n",
      "weekend        0.0206      0.038      0.538      0.590      -0.054       0.095\n",
      "heavy_rain    -0.0654      0.121     -0.539      0.590      -0.303       0.172\n",
      "==============================================================================\n",
      "Omnibus:                  1975635.996   Durbin-Watson:                   1.374\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):     177153163645.361\n",
      "Skew:                          38.616   Prob(JB):                         0.00\n",
      "Kurtosis:                    2483.913   Cond. No.                         7.85\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X1 = merged_df[['rush_hour', 'late_night', 'weekend', 'heavy_rain']]\n",
    "X2 = merged_df[['rush_hour']]\n",
    "y1 = merged_df['normalized_price']\n",
    "y2 = merged_df['surge_multiplier']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model1 = sm.OLS(y1, X1).fit()\n",
    "\n",
    "print(model.summary())\n",
    "#print(weather_df.shape[0])\n",
    "#print(merged_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da37c54e-0d12-416a-8cec-3dda4f118f82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxg\u001b[39;00m\n\u001b[1;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m merged_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrush_hour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlate_night\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurge_multiplier\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xg\n",
    "\n",
    "X = merged_df[['rush_hour', 'late_night', 'day_of_week']]\n",
    "y = merged_df['surge_multiplier']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
